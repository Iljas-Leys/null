{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76c787d0",
   "metadata": {},
   "source": [
    "Worked on by:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51d4aff",
   "metadata": {},
   "source": [
    "Clean the data\n",
    "\n",
    "This is very important on both datasets as you don't control the field-names yourself.\n",
    "\n",
    "    Rename columns to remove spaces from the name and make them all lowercase.\n",
    "    Look for the Na-values. Fix them if possible, using a couple of techniques before deciding which is best.\n",
    "    Look for the Outliers. Fix them if needed, using a couple of techniques before deciding which is best.\n",
    "    Look for (ordered) categoricals and label them as such.\n",
    "\n",
    "Exploratory data analysis\n",
    "\n",
    "    Show the outliers and try to explain them.\n",
    "    Draw some graphs about features you find interesting.\n",
    "    Look for correlations in your data.\n",
    "\n",
    "Repeat\n",
    "\n",
    "Both phases (cleaning and exploring) aren't two different steps in a process, but rather one large fuzzy mess of code. Something like:\n",
    "\n",
    "    I'll give all the Na's the mean value.\n",
    "    My graphs look strange, what is this peak doing at the mean?\n",
    "    Is there a correlation between the value that has a lot of Na's and another column?\n",
    "    Let's use the other column to fill in the Na's!\n",
    "\n",
    "In the upcoming steps of this project you'll put all the really good code together to make one final import, but for now poke the data and see what happens.\n",
    "Final loading and preparing\n",
    "\n",
    "Once you've cleaning and exploring and cleaning and exploring you'll lose track of the necessary steps and the optional steps. It's also possible that you did some cleaning that wasn't needed (e.g predict a field that should have been left empty).\n",
    "\n",
    "So end up your cleaning by creating a notebook that contains all the code to go from rough data to prepared data without any of the graphs.\n",
    "\n",
    "This has to be done for all both datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97a1a17",
   "metadata": {},
   "source": [
    "# Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d2de95",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas matplotlib numpy openpyxl seaborn scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9a5ec2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def parse_custom_date(date_str):\n",
    "    date_str = str(date_str).strip()  # Convert to string and strip spaces\n",
    "    \n",
    "    # Handle empty or nan-like values\n",
    "    if date_str in ['nan', 'NaN', '', None]:\n",
    "        return pd.NaT\n",
    "    \n",
    "    # Length checks (you can adjust if needed)\n",
    "    length = len(date_str)\n",
    "    \n",
    "    try:\n",
    "        if length == 10 and '-' in date_str:  # Format YYYY-MM-DD, e.g. 2001-01-01 or 2025-01-01\n",
    "            return pd.to_datetime(date_str, format='%Y-%m-%d')\n",
    "        elif length == 11 and '-' in date_str:  # Format DD-MMM-YYYY e.g. 01-JAN-2019\n",
    "            return pd.to_datetime(date_str, format='%d-%b-%Y')\n",
    "        elif length == 9 and '-' in date_str:  # Format DD-Mmm-YY e.g. 01-Jan-23\n",
    "            return pd.to_datetime(date_str, format='%d-%b-%y')\n",
    "        else:\n",
    "            # Fallback to pandas default parsing\n",
    "            return pd.to_datetime(date_str, errors='coerce')\n",
    "    except Exception:\n",
    "        return pd.NaT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6455912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows combined: 434014\n",
      "Missing dates after parsing: 0\n",
      "434014\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "path = './demanddata/'\n",
    "files = [f for f in os.listdir(path) if f.endswith('.csv')]\n",
    "\n",
    "dfs = []\n",
    "\n",
    "for file in files:\n",
    "    temp_df = pd.read_csv(os.path.join(path, file))\n",
    "    temp_df['SETTLEMENT_DATE'] = temp_df['SETTLEMENT_DATE'].apply(parse_custom_date)\n",
    "    dfs.append(temp_df)\n",
    "\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "print(f\"Total rows combined: {len(df)}\")\n",
    "print(f\"Missing dates after parsing: {df['SETTLEMENT_DATE'].isna().sum()}\")\n",
    "\n",
    "print(len(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c104478",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = [col.lower().replace(' ', '_') for col in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acc2861a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure date is datetime\n",
    "df['settlement_date'] = pd.to_datetime(df['settlement_date'])\n",
    "\n",
    "# Fill generation/flow columns missing values with zero\n",
    "cols_fill_zero = [\n",
    "    'embedded_wind_generation', 'embedded_wind_capacity',\n",
    "    'embedded_solar_generation', 'embedded_solar_capacity',\n",
    "    'ifa2_flow', 'britned_flow', 'east_west_flow',\n",
    "    'nemo_flow', 'nsl_flow', 'eleclink_flow',\n",
    "    'viking_flow', 'greenlink_flow','moyle_flow'\n",
    "]\n",
    "df[cols_fill_zero] = df[cols_fill_zero].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8723b950",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['scottish_transfer','nsl_flow', 'eleclink_flow','greenlink_flow','viking_flow','east_west_flow','nemo_flow','ifa2_flow'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41cbcf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['settlement_date'] >= '2006-01-01'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18ed5fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\AppData\\Local\\Temp\\ipykernel_14644\\3494621182.py:1: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df['tsd'] = df['tsd'].fillna(method='ffill')\n"
     ]
    }
   ],
   "source": [
    "df['tsd'] = df['tsd'].fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbd4d368",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['settlement_period'] <= 48]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ba1a665",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df.loc[df['tsd'] == 0, 'tsd'] = np.nan\n",
    "\n",
    "df['tsd'] = df['tsd'].interpolate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19f32fa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>settlement_date</th>\n",
       "      <th>settlement_period</th>\n",
       "      <th>nd</th>\n",
       "      <th>tsd</th>\n",
       "      <th>england_wales_demand</th>\n",
       "      <th>embedded_wind_generation</th>\n",
       "      <th>embedded_wind_capacity</th>\n",
       "      <th>embedded_solar_generation</th>\n",
       "      <th>embedded_solar_capacity</th>\n",
       "      <th>non_bm_stor</th>\n",
       "      <th>pump_storage_pumping</th>\n",
       "      <th>ifa_flow</th>\n",
       "      <th>britned_flow</th>\n",
       "      <th>moyle_flow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>38596</td>\n",
       "      <td>39660.0</td>\n",
       "      <td>34982</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>295</td>\n",
       "      <td>1997</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-169.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006-01-01</td>\n",
       "      <td>2</td>\n",
       "      <td>38829</td>\n",
       "      <td>39897.0</td>\n",
       "      <td>35312</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>299</td>\n",
       "      <td>1997</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-169.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006-01-01</td>\n",
       "      <td>3</td>\n",
       "      <td>38456</td>\n",
       "      <td>39599.0</td>\n",
       "      <td>35018</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>374</td>\n",
       "      <td>1998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-169.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006-01-01</td>\n",
       "      <td>4</td>\n",
       "      <td>37401</td>\n",
       "      <td>38823.0</td>\n",
       "      <td>34054</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>653</td>\n",
       "      <td>1998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-169.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006-01-01</td>\n",
       "      <td>5</td>\n",
       "      <td>36586</td>\n",
       "      <td>37937.0</td>\n",
       "      <td>33297</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>582</td>\n",
       "      <td>1998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-169.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  settlement_date  settlement_period     nd      tsd  england_wales_demand  \\\n",
       "0      2006-01-01                  1  38596  39660.0                 34982   \n",
       "1      2006-01-01                  2  38829  39897.0                 35312   \n",
       "2      2006-01-01                  3  38456  39599.0                 35018   \n",
       "3      2006-01-01                  4  37401  38823.0                 34054   \n",
       "4      2006-01-01                  5  36586  37937.0                 33297   \n",
       "\n",
       "   embedded_wind_generation  embedded_wind_capacity  \\\n",
       "0                       0.0                     0.0   \n",
       "1                       0.0                     0.0   \n",
       "2                       0.0                     0.0   \n",
       "3                       0.0                     0.0   \n",
       "4                       0.0                     0.0   \n",
       "\n",
       "   embedded_solar_generation  embedded_solar_capacity  non_bm_stor  \\\n",
       "0                        0.0                      0.0            0   \n",
       "1                        0.0                      0.0            0   \n",
       "2                        0.0                      0.0            0   \n",
       "3                        0.0                      0.0            0   \n",
       "4                        0.0                      0.0            0   \n",
       "\n",
       "   pump_storage_pumping  ifa_flow  britned_flow  moyle_flow  \n",
       "0                   295      1997           0.0      -169.0  \n",
       "1                   299      1997           0.0      -169.0  \n",
       "2                   374      1998           0.0      -169.0  \n",
       "3                   653      1998           0.0      -169.0  \n",
       "4                   582      1998           0.0      -169.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d49a3567",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('cleaned_data.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_pycaret",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
